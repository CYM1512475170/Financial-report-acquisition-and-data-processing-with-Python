{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38464bit9379dd402be645a4a272fa7043f0c61f",
   "display_name": "Python 3.8.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlrd #（excel read）来读取Excel文件\n",
    "import xlwt #（excel write）来生成Excel文件\n",
    "workbook = xlwt.Workbook()  # 新建一个工作簿\n",
    "sheet = workbook.add_sheet(\"sheet1\")  # 在工作簿中新建一个表格\n",
    "def write_excel_xls(path,value,inum):\n",
    "    index = len(value)  # 获取需要写入数据的行数\n",
    "    # print(\"index is\",index)\n",
    "    for num in range(0, index):\n",
    "        sheet.write(inum,num,value[num])\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    print(\"~~xls格式表格写入数据成功！~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "    print(\"~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "C:/Temp/stock.txt\n"
    }
   ],
   "source": [
    "# coding=UTF-8\n",
    "file_folder1= \"C:/\"\n",
    "file_folder= file_folder1+\"Temp/stock.txt\"\n",
    "# file_name=\"test.xls\";f=open(file_folder1+'stock_electricity_3.txt')\n",
    "# file_name=\"沪深300.xls\";f=open(file_folder1+'sh_sz_300.txt')\n",
    "print(file_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(file_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "stock is ['sz600600', 'sh000123', 'sh000449', 'sh000666']\n"
    }
   ],
   "source": [
    "stock = []\n",
    "for line in f.readlines():\n",
    "    #print(line,end = '')\n",
    "    line = line.replace('\\n','')\n",
    "    stock.append(line)\n",
    "f.close()\n",
    "print('stock is',stock[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iinum = 1\n",
    "for each in stock:\n",
    "# for each in stock:\n",
    "    print(\"**********************************\")\n",
    "    print(\"******\",iinum,\"******\",len(stock))\n",
    "    print(\"**********************************\")\n",
    "    # print(each[2:])\n",
    "    each1=each[2:8]\n",
    "    print('1',each)\n",
    "    #新浪行情中心#新浪行情中心#新浪行情中心\n",
    "    url_sina_introduction='http://vip.stock.finance.sina.com.cn/corp/go.php/vCI_CorpInfo/stockid/'+each1+'.phtml'\n",
    "    url_sina_report='http://vip.stock.finance.sina.com.cn/corp/go.php/vCB_Bulletin/stockid/'+each1+'/page_type/ndbg.phtml'\n",
    "    #网易财经#网易财经#网易财经#网易财经\n",
    "    url_netease_index='http://quotes.money.163.com/'+each1+'.html' #网易个股主页\n",
    "    url_netease_introduction='http://quotes.money.163.com/f10/gszl_'+each1+'.html#11c01#' #网易个股公司简介\n",
    "    url_netease_report='http://quotes.money.163.com/f10/gsgg_'+each1+',dqbg.html' #网易公司定期报告，无法下载，但是有详细全文内容很全\n",
    "    #网易财经如宁波韵升( 600366) 公司公告http://quotes.money.163.com/f10/gsgg_600366,dqbg.html\n",
    "    url_xueqiu_index=\"https://xueqiu.com/S/\"+each[0:8]\n",
    "    url_eastmoney_report=\"http://data.eastmoney.com/notices/stock/300644.html\"#年报混编了，不方便下载\n",
    "    url_ifeng='http://app.finance.ifeng.com/data/stock/dqbg.php?symbol='+each1#凤凰财经的年报链接，不过无法访问了暂时\n",
    "    print('###########公司信息##############################')\n",
    "    headers = {'User-Agent': 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'}\n",
    "    # print(url)\n",
    "    response_sina_introduction = requests.get(url_sina_introduction, headers=headers)\n",
    "    response_sina_introduction.encoding = 'gbk'  # 解决乱码问题\n",
    "    html_text_sina_introduction = response_sina_introduction.text\n",
    "    # 开始爬虫# 开始爬虫# 开始爬虫# 开始爬虫# 开始爬虫\n",
    "    import lxml\n",
    "    from lxml import etree\n",
    "    selector = etree.HTML(html_text_sina_introduction)\n",
    "    title_sina_introduction = selector.xpath('//table/tr/td//text()')\n",
    "    # 去除其中的冒号# 去除其中的冒号\n",
    "    title_1_sina_introduction = []\n",
    "    for i in title_sina_introduction:\n",
    "        i = i.strip()\n",
    "        i = i.strip('：')\n",
    "        title_1_sina_introduction.append(i)\n",
    "    print(\"title_1_sina_introduction\", title_1_sina_introduction[0:4])\n",
    "    # 去除其中的冒号# 去除其中的冒号\n",
    "    print('###########公司信息##############################')\n",
    "    print('###########年报审计的会计师事务所#################')\n",
    "\n",
    "    req = urllib.request.Request(url_sina_report)\n",
    "    print('2',each)\n",
    "    req.add_header('User-Agent','Mozilla/5.0 (Windows NT 6.2; rv:16.0) Gecko/20100101 Firefox/16.0')\n",
    "    page = urllib.request.urlopen(req)\n",
    "####    time.sleep(random.random() * 15)\n",
    "    time.sleep(random.random() * 15)\n",
    "####    time.sleep(random.random() * 15)\n",
    "    print('3',each)\n",
    "\n",
    "\n",
    "    #嗅探年报的网站链接    #嗅探年报的网站链接\n",
    "    try:\n",
    "        html = page.read().decode('gbk');target = r'&id=[_0-9_]{7}';target_list = re.findall(target,html)\n",
    "        sid = each1;target_url = 'http://vip.stock.finance.sina.com.cn/corp/view/vCB_AllBulletinDetail.php?stockid=' + sid\n",
    "        if len(target_list)>0:\n",
    "            year = 2018;each2018 = target_list[0];target_url_2018=target_url+each2018\n",
    "            print('----2018----',each1,year,'年报链接,',target_url_2018)\n",
    "    # 嗅探年报的网站链接    #嗅探年报的网站链接\n",
    "\n",
    "    ### 爬取会计师事务所### 爬取会计师事务所\n",
    "    ####    time.sleep(random.random() * 15)\n",
    "            time.sleep(random.random() *15)\n",
    "    ####    time.sleep(random.random() * 15)\n",
    "            import requests\n",
    "            headers = {'User-Agent': 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'}\n",
    "            response = requests.get(target_url_2018, headers=headers)\n",
    "            response.encoding = 'gbk'  # 解决乱码问题\n",
    "            html_text = response.text\n",
    "            import lxml\n",
    "            from lxml import etree\n",
    "            selector = etree.HTML(html_text)\n",
    "            title = selector.xpath('//table/tr/td//text()')#2018年会计师事务所\n",
    "            # title = selector.xpath('//tbody/tr/td//text()')#2017\n",
    "            # 去除其中的冒号\n",
    "            title_1 = []\n",
    "            for i in title:\n",
    "                i = i.strip()\n",
    "                i = i.strip('：')\n",
    "                # title_1.append(i)\n",
    "                for j in i.split():\n",
    "                    # print(\"--------------\",j)\n",
    "                    title_1.append(j)\n",
    "                # title_1.append(i)\n",
    "            # print(\"title_1\", title_1[00:1500])\n",
    "            time_now=int(time.time())\n",
    "            time_now=str(time_now)[0:7]\n",
    "            path1 =file_folder+time_now+\"_\"+str(year)+file_name+'.xls'\n",
    "            print(path1)\n",
    "            for title in range(len(title_1)):\n",
    "                if title_1[title].find('境内会计师事务所名称')>-1:\n",
    "                    for i in range(1):\n",
    "                    # for i in range(20):\n",
    "                        print(i,title_1[title+i])\n",
    "                    # 存入excel\n",
    "                    # write_excel_xls(path1, [each[0:7], each[8:], year,target_url, title_1[title],title_1[title+1],title_1[title+2],title_1[title+3],title_1[title+4],title_1[title+5],title_1[title+6],title_1[title+7],title_1[title+8],title_1[title+9],title_1[title+10],title_1[title+11],title_1[title+12]]+title_1_sina_introduction, iinum)\n",
    "                    # workbook.save(path1)  # 保存工作簿\n",
    "                    # 存入excel\n",
    "            iinum=iinum+1\n",
    "    ### 爬取会计师事务所### 爬取会计师事务所\n",
    "\n",
    "\n",
    "\n",
    "    ###下载年报 ###下载年报 ###下载年报\n",
    "        # if len(target_list) > 0:\n",
    "        #     year = 2018;\n",
    "        #     each2018 = target_list[0];\n",
    "        #     target_url_2018 = target_url + each2018\n",
    "        #     os.mkdir('./'+file_name+each[2:])\n",
    "            time.sleep(random.random() * 8)\n",
    "            treq = urllib.request.Request(target_url_2018)\n",
    "            treq.add_header('User-Agent','Mozilla/5.0 (Windows NT 6.2; rv:16.0) Gecko/20100101 Firefox/16.0')\n",
    "            tpage = urllib.request.urlopen(treq)\n",
    "            time.sleep(random.random() * 3)\n",
    "            try:\n",
    "                thtml = tpage.read().decode('gbk')\n",
    "                #print(thtml)\n",
    "                file_url = re.search('http://file.finance.sina.com.cn/211.154.219.97:9494/.*?PDF',thtml)\n",
    "                print(\"--9--file_url is\",file_url.group(0))\n",
    "\n",
    "                try:\n",
    "                    #print(file_url.group(0))\n",
    "                    local = './'+file_name+each[2:]+'/'+each[2:]+'2018年年报'+'.pdf'\n",
    "                    # local = './'+each+'/'+file_url.group(0).split(\"/\")[-4]+'.pdf'\n",
    "                    # local = './'+each+'/'+file_url.group(0).split(\"/\")[-1]+'.pdf'\n",
    "                    # local = './'+sid+'/'+file_url.group(0).split(\"/\")[-1]+'.pdf'\n",
    "                    print(\"10 local is\",local)\n",
    "                    #调试用作文件占位\n",
    "                    #open(local, 'wb').write(b'success')\n",
    "                    print('11',each1,'local',local)\n",
    "                    # urllib.request.urlretrieve(file_url.group(0),local,None)\n",
    "                except:\n",
    "                    print('2018PDF失效;'+target_url)\n",
    "            except:\n",
    "                print(each1,'2018年报下载页面编码错误;'+target_url)\n",
    "        if len(target_list)>3:\n",
    "            print('----2015----',each1,'2015年target_list',target_list[3])\n",
    "            each2015 = target_list[3];target_url_2015=target_url+each2015\n",
    "            # year=2017;each2017=target_list[1]\n",
    "            time.sleep(random.random() * 8)\n",
    "            treq_2015 = urllib.request.Request(target_url_2015)\n",
    "            treq_2015.add_header('User-Agent','Mozilla/5.0 (Windows NT 6.2; rv:16.0) Gecko/20100101 Firefox/16.0')\n",
    "            tpage = urllib.request.urlopen(treq_2015)\n",
    "            time.sleep(random.random() * 8)\n",
    "            try:\n",
    "                thtml_2015 = tpage.read().decode('gbk')\n",
    "                #print(thtml)\n",
    "                file_url_2015 = re.search('http://file.finance.sina.com.cn/211.154.219.97:9494/.*?PDF',thtml_2015)\n",
    "                print(\"--2015--file_url is\",file_url_2015.group(0))\n",
    "\n",
    "                try:\n",
    "                    #print(file_url.group(0))\n",
    "                    local = './'+file_name+each[2:]+'/'+each[2:]+'2015年年报'+'.pdf'\n",
    "                    # report_year=(file_url_2015.group(0).split(\"/\")[-4])\n",
    "                    # local = './'+file_name+each+'/'+report_year+'.pdf'\n",
    "                    # local = './'+each+'/'+file_url.group(0).split(\"/\")[-1]+'.pdf'\n",
    "                    # local = './'+sid+'/'+file_url.group(0).split(\"/\")[-1]+'.pdf'\n",
    "                    print(\"2015 local is\",local)\n",
    "                    #调试用作文件占位\n",
    "                    #open(local, 'wb').write(b'success')\n",
    "                    print('2015',each1,'local',local)\n",
    "                    urllib.request.urlretrieve(file_url_2015.group(0),local,None)\n",
    "                except:\n",
    "                    print('2015PDF失效;'+target_url)\n",
    "            except:\n",
    "                print(each1,'2015年报下载页面编码错误;'+target_url)\n",
    "\n",
    "    ###下载年报 ###下载年报 ###下载年报\n",
    "    except:\n",
    "        print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "        print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "        print(each,'年报列表页面编码错误;',path1,str(year)+title_1[0])\n",
    "        print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')\n",
    "        print('@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@')"
   ]
  }
 ]
}